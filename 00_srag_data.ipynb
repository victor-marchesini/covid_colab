{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp srag_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SRAG Data\n",
    "\n",
    "> Get SRAG data from opendatasus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.showdoc import *\n",
    "import os.path\n",
    "import pandas as pd\n",
    "import ssl\n",
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def get_last_bd_srag_csv_url(year=2021):\n",
    "    \n",
    "    available_years = (2020,2021)\n",
    "    if year not in available_years:\n",
    "        print('year not valid. Available years:',available_years)\n",
    "        return\n",
    "    \n",
    "    # Se nao achar, retorna última url encontrada\n",
    "    srag_url = f'https://s3-sa-east-1.amazonaws.com/ckan.saude.gov.br/SRAG/{year}/INFLUD-29-03-2021.csv'\n",
    "    \n",
    "    context = ssl._create_unverified_context() # To aviod ssl error\n",
    "    html_page = urlopen(f'https://opendatasus.saude.gov.br/dataset/bd-srag-{year}', context=context)\n",
    "    soup = BeautifulSoup(html_page, features=\"lxml\")\n",
    "    for link in soup.findAll('a'):\n",
    "        url = link.get('href')\n",
    "        (filename, ext) = os.path.splitext(url)\n",
    "        if ext.lower() == '.csv':\n",
    "            srag_url = url\n",
    "            print(f'\\nNew csv file url: <{srag_url}>')\n",
    "    \n",
    "    return srag_url\n",
    "\n",
    "\n",
    "\n",
    "def get_srag_data(year=2021,update=False,treat=True,selected_columns='BASIC',aditional_columns=[]):\n",
    "    \n",
    "    sep = ';'\n",
    "    quotechar = '\"'\n",
    "    \n",
    "    fname = f'data/SRAG/INFLUD{year}.csv'\n",
    "    if os.path.isfile(fname) and not update:\n",
    "        print(f'\\nReading OpenDataSus from local file <{fname}>. If you prefer to download last version, set \"update=True\".\\n')\n",
    "        df = pd.read_csv(fname,dtype=object)\n",
    "    else:\n",
    "        url = get_last_bd_srag_csv_url(year)\n",
    "        print(f'\\nDownloading from <{url}> ... ', end='')\n",
    "        df = pd.read_csv(url,sep=sep,quotechar=quotechar,dtype=object)\n",
    "        df.to_csv(fname,index=False)\n",
    "        print('complete!\\n')\n",
    "        \n",
    "    if treat:\n",
    "        df = treat_srag_data(df,selected_columns,aditional_columns)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def get_cities_states_dictionaries():\n",
    "    ''' Returns 2 dictionaries: \n",
    "    1. cities_dict - city code (6 dig): city name\n",
    "    2. states_dict - state code (2 dig): state name\n",
    "    '''\n",
    "    fname = 'data/IBGE/RELATORIO_DTB_BRASIL_MUNICIPIO.ods'\n",
    "    df = pd.read_excel(fname,dtype=object)\n",
    "    df['cod_municipio'] = df['Código Município Completo'].str[:6]\n",
    "    cities_dict = df.set_index('cod_municipio')['Nome_Município'].to_dict()\n",
    "    states_dict = df[['UF','Nome_UF']].groupby('UF').first()['Nome_UF'].to_dict()\n",
    "    return cities_dict, states_dict\n",
    "\n",
    "def treat_srag_data(df,selected_columns='BASIC',aditional_columns=[]):\n",
    "    \"Select columns, set types and replace values.\"\n",
    "    df = df.copy()\n",
    "    date_cols = ['DT_SIN_PRI','DT_EVOLUCA','DT_NASC','DT_ENTUTI']\n",
    "    cities_cols = ['CO_MUN_RES','CO_MU_INTE','CO_MUN_NOT']\n",
    "#     str_cols = cities_cols\n",
    "    \n",
    "    if selected_columns != 'ALL':\n",
    "        basic_cols = date_cols + cities_cols\n",
    "        basic_cols += ['SEM_PRI', 'EVOLUCAO', 'CLASSI_FIN','CLASSI_OUT',                \n",
    "                      'NU_IDADE_N','CS_RACA', 'CS_ESCOL_N', 'CS_SEXO',\n",
    "#                       'ID_MN_RESI','ID_MN_ITE','ID_MUNICIP',\n",
    "                      'UTI', 'SUPORT_VEN']\n",
    "    \n",
    "        if selected_columns == 'BASIC':\n",
    "            cols = basic_cols\n",
    "        else:\n",
    "            cols = basic_cols + list(aditional_columns)\n",
    "        df = df[cols]\n",
    "        \n",
    "    df_cols = df.columns\n",
    "    numeric_cols = ['SEM_PRI','NU_IDADE_N']\n",
    "#     numeric_cols = list(set(df_cols) - set(date_cols) - set(str_cols))\n",
    "    for col in date_cols:\n",
    "        df[col] = pd.to_datetime(df[col], errors='coerce',dayfirst=True)\n",
    "\n",
    "    for col in numeric_cols:\n",
    "        df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "    \n",
    "    \n",
    "    cities_dict,states_dict = get_cities_states_dictionaries()\n",
    "    regions_dict = {'1':'Norte',\n",
    "                    '2':'Nordeste',\n",
    "                    '3':'Sudeste',\n",
    "                    '4':'Sul',\n",
    "                    '5':'Centro-Oeste' }\n",
    "    \n",
    "    for col in cities_cols:\n",
    "#         city_name_col = col[3:]\n",
    "        sufix_index = col.index('_',3)\n",
    "        city_name_col = 'MUN' + col[sufix_index:]\n",
    "        state_name_col = 'UF' + col[sufix_index:]\n",
    "        region_name_col = 'REGIAO' + col[sufix_index:]\n",
    "        df[city_name_col] = df[col].apply(lambda x: cities_dict.get(x,'n.d.'))\n",
    "        df[state_name_col] = df[col].str[:2].apply(lambda x: states_dict.get(x,'n.d.'))\n",
    "        df[region_name_col] = df[col].str[0].apply(lambda x: regions_dict.get(x,'n.d.'))\n",
    "        \n",
    "    evolucao_dict = {'1':'cura',\n",
    "                     '2':'obito',\n",
    "                     '3':'obito_outras_causas',\n",
    "                     '9':'ignorado' }\n",
    "    classi_fin_dict = {'1':'cura',\n",
    "                     '2':'obito',\n",
    "                     '3':'obito_outras_causas',\n",
    "                     '9':'ignorado' }\n",
    "\n",
    "    df['EVOLUCAO'] = df['EVOLUCAO'].apply(lambda x: evolucao_dict.get(x,'n.d.'))\n",
    "    df['CLASSI_FIN'] = df['CLASSI_FIN'].apply(lambda x: classi_fin_dict.get(x,'n.d.'))\n",
    "    dict_cols = ['EVOLUCAO','CLASSI_FIN']\n",
    "    \n",
    "    other_cols = list(set(df_cols) - set(date_cols) - set(numeric_cols) - set(cities_cols) - set(dict_cols))\n",
    "    df[other_cols] = df[other_cols].fillna('n.d.')\n",
    "#     for col in str_cols:\n",
    "#         df[col] = df[col].fillna('n.d.')\n",
    "    \n",
    "\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "New csv file url: <https://s3-sa-east-1.amazonaws.com/ckan.saude.gov.br/SRAG/2021/INFLUD21-29-03-2021.csv>\n",
      "\n",
      "Downloading from <https://s3-sa-east-1.amazonaws.com/ckan.saude.gov.br/SRAG/2021/INFLUD21-29-03-2021.csv> ... complete!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_srag = get_srag_data(treat=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "421368"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_srag.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert df_srag.shape[0]>=421368\n",
    "assert df_srag.shape[1]==154"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = treat_srag_data(df_srag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert df.shape[0]==df_srag.shape[0]\n",
    "assert df.shape[1]==26"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
